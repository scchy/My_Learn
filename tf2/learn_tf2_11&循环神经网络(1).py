# python3.6
# Create date: 2020-06-13
# Function: 19年11月最新-《TensorFlow+2.0深度学习算法实战教材》

import tensorflow as tf 
import math
import abc
import numpy as np

# ======== 目录 ==========
# &11 循环神经网络
#   - 11.1 序列表示方法
#   - 11.2 循环神经网络
# ========================

# =======================================================================================================
#                                           第十一章   循环神经网络
# =======================================================================================================



"""
自然节的信号除了具有空间维度之外，还有一个时间维度。具有时间维度的信号非常常见。
比如我们正在阅读的文本，说话时发出的语音信号，随着时间变化的股市参数等

"""

# 11.1 序列表示方法
# ---------------------------------------------------
"""
考虑某件商品A在1-6月之间的价格变化趋势，我们记为一维向量[x1, x2, x3, x4, x5, x6]
它的shape为[6], 如果要表示n件商品在1月到6月之间的价格变化趋势，可以记为2维张量 [n, 6]

# b为序列数量， s为序列长度
[b, s]
但是很多信号并不能直接用一个标量数值表示。 比如每个时间戳产生长度为f的特征
[b, s, f]
"""
"""
onehot embedding存在很多问题。所以会有word vevtor使得语义层面的相关性能够很好地在word vector上面体现出来。
一个衡量表示向量的尺度就是余弦相关度。

"""
## 11.1.1 Embedding 层
"""
在神经网络中，单词的表示向量可以直接通过训练的方式得到，我们把单词的标识层叫做Embedding层。
Embedding层负责把单词编码为某个向量vec, 它接受的是采用数字编码的单词idx，

Embedding层实现起来非常简单，通过一个shape为[Nvocab, f]的查询表table,对任意的单词idx，只需要
查询到对应位置上的向量返回即可：
vec = table[idx]

Embedding层是可训练的， 他可放置在神经网络之前，完成单词到向量的装换，得到的表示向量可以继续通过神经网络
完成后续任务，并计算误差L，采用梯度下降来实现端到端的训练。
"""
import tensorflow as tf
from tensorflow.keras import layers
# layers.Embedding(Nvocab, f)
x = tf.range(10)
x = tf.random.shuffle(x)
net = layers.Embedding(10, 4)
out = net(x)
out
## 11.1.2 预训练的词向量
"""
Embedding层的查询表是随机初始化的，需要从空开始训练。实际上，我们可以使用预训练的Word embeddig模型
来得到单词的表示方式，基于训练模型的词向量相当于迁移整个语音空间的知识，往往能得到更好的性能。
"""
# 从预训练模型中加载词向量表
embed_glove = load_embed('glovr.6B.59d.txt')
# 直接利用预训练的词向量初始化Embedding层

# 11.2 循环神经网络
# ---------------------------------------------------


