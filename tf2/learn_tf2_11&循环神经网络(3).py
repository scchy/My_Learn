# python3.6
# Create date: 2020-12-20
# Function: 19年11月最新-《TensorFlow+2.0深度学习算法实战教材》


# ======== 目录 ==========
# &11 循环神经网络
#   - 11.6 梯度弥散和梯度爆炸
# ========================


# =======================================================================================================
#                                           第十一章   循环神经网络
# =======================================================================================================

# 11.6 梯度弥散和梯度爆炸
# ---------------------------------------------------
"""

循环神经网络的训练并不稳定，网络的深度不能任意的加深。为什么RNN会出现这种情况呢？
关键在于其梯度下降的时候的连乘。d(ht)/d(hi)包含了Whh的连乘运算，当Whh的做大特征值小于1时，多次连乘
会使得d(ht)/d(hi)的元素接近于0；若d(ht)/d(hi) > 1 ,多次连乘运算会使得d(ht)/d(hi)的元素值爆炸式增长

"""
def show_desc(scale=1):
  W = tf.one([2,2]) * scale
  eigenvalyes = tf.linalg.eigh(W)[0] # 计算特征值

  val = [W]
  for i in range(10):
    val.append([val[-1]@W])

  # 计算L2范数
  norm = list(
    map(lambda x:tf.norm(x).numpy(), val)
  )
  plt.plot(range(1,12), norm)
  plt.show()
  
## 11.6.1 梯度裁剪
 


