{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# einsum\n",
    "```python\n",
    "a = torch.rand(2, 3)\n",
    "b = torch.rand(3, 4)\n",
    "c = torch.einsum('ik,kj->ij', [a, b])\n",
    "```\n",
    "\n",
    "- rule1: 在不同输入之间重复出现的索引表示，把输入张量沿着该维度做乘法操作，把`a`和`b`沿着`k`这个**维度相乘**\n",
    "- rule2: 只出现在`equation`箭头左边的索引，表示中间计算结果需要在这个维度上**求和**，即求和索引\n",
    "- rule3: equation 箭头右边的索引顺序可以是任意的\n",
    "- spRule1: equation 中支持`...`省略号，用于表示用户不关心的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 4, 8]), tensor([0, 4, 8]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(9).reshape(3, 3)\n",
    "torch.einsum('ii->i', [a]), torch.diagonal(a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(12), tensor(12))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diagonal sum\n",
    "torch.einsum('ii', [a]), torch.diagonal(a, 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- reduce sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(36), tensor(36))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij->', [a]), a.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- dim sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3, 12, 21]),\n",
       " tensor([ 3, 12, 21]),\n",
       " tensor([ 9, 12, 15]),\n",
       " tensor([ 9, 12, 15]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij->i', [a]), a.sum(dim=1), torch.einsum('ij->j', [a]), a.sum(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- 矩阵向量乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 5, 14]), tensor([ 5, 14]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(6).reshape(2, 3)\n",
    "b = torch.arange(3)\n",
    "torch.einsum('ij,j->i', [a, b]), a @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- 矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5603, 0.9049, 0.4620, 0.0556],\n",
       "         [0.4624, 1.1891, 0.5609, 0.2867]]),\n",
       " tensor([[0.5603, 0.9049, 0.4620, 0.0556],\n",
       "         [0.4624, 1.1891, 0.5609, 0.2867]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2, 3)\n",
    "b = torch.rand(3, 4)\n",
    "\n",
    "torch.einsum('ik,kj->ij', [a, b]), a @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6- 向量内积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(14), tensor(14))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3)\n",
    "b = torch.arange(3, 6)\n",
    "torch.einsum('i,i->', [a, b]), (a * b).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7- 对应元素相乘reduce sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(145), tensor(145))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(6).reshape(2, 3)\n",
    "b = torch.arange(6, 12).reshape(2, 3)\n",
    "torch.einsum('ij,ij->', [a, b]), (a * b).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8- 向量外积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0,  0],\n",
       "         [ 3,  4,  5,  6],\n",
       "         [ 6,  8, 10, 12]]),\n",
       " tensor([[ 0,  0,  0,  0],\n",
       "         [ 3,  4,  5,  6],\n",
       "         [ 6,  8, 10, 12]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3)\n",
    "b = torch.arange(3, 7)  # [3, 4, 5, 6]\n",
    "torch.einsum('i,j', [a, b]), torch.repeat_interleave(a, len(b)).reshape(len(a), len(b)) * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9- batch 矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 4.1401,  1.1497,  3.5784, -0.4273],\n",
       "          [-1.2875,  0.5160,  2.2896,  3.6230],\n",
       "          [ 2.1326, -0.6485,  1.5664,  1.2608]],\n",
       " \n",
       "         [[ 0.1734,  0.6592, -0.4031,  2.1443],\n",
       "          [ 0.0825, -1.2430,  2.9188,  1.1550],\n",
       "          [-1.4477, -2.0411, -0.7977, -1.7201]]]),\n",
       " tensor([[[ 4.1401,  1.1497,  3.5784, -0.4273],\n",
       "          [-1.2875,  0.5160,  2.2896,  3.6230],\n",
       "          [ 2.1326, -0.6485,  1.5664,  1.2608]],\n",
       " \n",
       "         [[ 0.1734,  0.6592, -0.4031,  2.1443],\n",
       "          [ 0.0825, -1.2430,  2.9188,  1.1550],\n",
       "          [-1.4477, -2.0411, -0.7977, -1.7201]]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2, 3, 5)\n",
    "b = torch.randn(2, 5, 4)\n",
    "torch.einsum('bik,bkj->bij', [a, b]), a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sccDeep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
